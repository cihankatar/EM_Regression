import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ðŸ“Œ 1. VERÄ°YÄ° OKUMA
file_path = "DATA_01.xlsx"
df_raw = pd.read_excel(file_path, sheet_name="Sayfa1", skiprows=3)

# ðŸ“Œ 2. VERÄ°YÄ° TEMÄ°ZLEME
columns = ["Thickness", "Frequency (GHz)", "S11_real", "S11_imag", "S22_real", "S22_imag", "epsR_real", "epsR_imag"]
df_clean = df_raw.iloc[2:, [2, 3, 4, 5, 6, 7, 10, 11]].copy()
df_clean.columns = columns
df_clean = df_clean.astype(float)

# ðŸ“Œ 3. Ã–ZELLÄ°KLER VE Ã‡IKTILARI AYIRMA
X = df_clean.iloc[:, :6].values  # Thickness, Frequency, S11_real, S11_imag, S22_real, S22_imag
y = df_clean.iloc[:, 6:].values  # epsR_real, epsR_imag

# ðŸ“Œ 4. TRAIN-TEST AYIRMA (%80 Train - %20 Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ðŸ“Œ 5. VERÄ°YÄ° NORMALÄ°ZE ETME
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train = scaler_X.fit_transform(X_train)
X_test = scaler_X.transform(X_test)
y_train = scaler_y.fit_transform(y_train)
y_test = scaler_y.transform(y_test)

# ðŸ“Œ 6. TORCH TENSORLERÄ°NE DÃ–NÃœÅžTÃœRME
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

# ðŸ“Œ 7. TRANSFORMER MODELÄ°
class TransformerRegressor(nn.Module):
    def __init__(self, input_size, d_model=64, nhead=4, num_layers=3, dim_feedforward=128):
        super(TransformerRegressor, self).__init__()
        
        # GiriÅŸ iÃ§in lineer katman (d_model boyutuna Ã§evirmek iÃ§in)
        self.input_layer = nn.Linear(input_size, d_model)
        
        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # Ã‡Ä±kÄ±ÅŸ katmanÄ±
        self.output_layer = nn.Linear(d_model, 2)  # 2 Ã§Ä±kÄ±ÅŸ: epsR_real, epsR_imag

    def forward(self, x):
        x = self.input_layer(x)  # Ä°lk lineer dÃ¶nÃ¼ÅŸÃ¼m
        x = x.unsqueeze(1)  # (batch_size, seq_len=1, d_model)
        x = self.transformer_encoder(x)  # Transformer Encoder'a gÃ¶nder
        x = x.squeeze(1)  # (batch_size, d_model)
        x = self.output_layer(x)  # Ã‡Ä±kÄ±ÅŸ katmanÄ±
        return x

# ðŸ“Œ 8. MODELÄ° BAÅžLATMA
input_dim = X_train.shape[1]
model = TransformerRegressor(input_size=input_dim)

# ðŸ“Œ 9. KAYIP FONKSÄ°YONU VE OPTÄ°MÄ°ZASYON
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ðŸ“Œ 10. MODELÄ° EÄžÄ°TME
epochs = 200
train_losses = []
val_losses = []

for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    
    # Forward Pass
    y_pred = model(X_train_tensor)
    loss = criterion(y_pred, y_train_tensor)
    
    # Backpropagation
    loss.backward()
    optimizer.step()
    
    train_losses.append(loss.item())

    # Validation Loss Hesaplama
    model.eval()
    with torch.no_grad():
        y_val_pred = model(X_test_tensor)
        val_loss = criterion(y_val_pred, y_test_tensor).item()
        val_losses.append(val_loss)

    # Her 10 epoch'ta bir ekrana yazdÄ±r
    if (epoch+1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{epochs}] - Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}")

# ðŸ“Œ 11. TEST METRÄ°KLERÄ° HESAPLAMA
model.eval()
with torch.no_grad():
    y_test_pred = model(X_test_tensor)
    test_loss = criterion(y_test_pred, y_test_tensor).item()
    y_test_pred = y_test_pred.numpy()
    y_test_true = y_test_tensor.numpy()

# ðŸ“Œ 12. REGRESYON METRÄ°KLERÄ°
mse = mean_squared_error(y_test_true, y_test_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_true, y_test_pred)
r2 = r2_score(y_test_true, y_test_pred)

# ðŸ“Œ 13. TEST SONUÃ‡LARINI YAZDIR
print("\nðŸ“Œ Test Set Metrics:")
print(f"âœ… MSE (Mean Squared Error): {mse:.4f}")
print(f"âœ… RMSE (Root Mean Squared Error): {rmse:.4f}")
print(f"âœ… MAE (Mean Absolute Error): {mae:.4f}")
print(f"âœ… RÂ² Score (R-Squared): {r2:.4f}")
print(f"âœ… Test Loss (MSE): {test_loss:.4f}")

# ðŸ“Œ 14. LOSS EÄžRÄ°SÄ°NÄ° Ã‡Ä°ZME
plt.figure(figsize=(8, 5))
plt.plot(train_losses, label="Train Loss", color='blue')
plt.plot(val_losses, label="Validation Loss", color='red')
plt.axhline(y=test_loss, color='green', linestyle='--', label=f"Test Loss: {test_loss:.4f}")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training & Validation Loss Curve")
plt.legend()
plt.grid()
plt.savefig("loss_curve_transformer.png")
plt.show()
